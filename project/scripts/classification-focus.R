# Summer Workshop Project: FOCUS #1
# ROC plots, sample classifications, and classifier performance 
# 30 May 2013

# Assignment: read about ROC curves and classification

# For each of ~40000 samples in the experiment data frame we have: 
#   - Human classification: crystal or not crystal (1 or 0) (we take this to be the true class),
#       experiment$human_crystal
#   - Machine classification: a probability generated by polling the machine classifier many times,
#     a continuous variable ranging from 0 to 1 ("classifier score"),
#       experiment$class3_crystal

# We can assess the following for our experiment dataset:
#   - true positives: human called it positive, so did classifier
#   - true negatives: human called it negative, so did classifier
#   - false positives: human called it negative, classifier positive
#   - false negatives: human called it positive, classifier negative

# To decide how the classifier performed on the data, we need to decide on a cutpoint or threshold. 
# Classifier values larger than the threshold are considered to be crystals; classifier
# values smaller than the threshold are considered not-crystals.

# We can find an optimal threshold that maximizes the number of correct classifications
# while minimizing the number of incorrect classifications. First we'll fiddle around with some
# thresholds to get a feel for it.

# -----------------------------------------------------------------


# 1. Make exploratory histograms of the classifier crystallization score and of the human crystal 
# assignment for the full dataset. Make note of the counts on the y axis for each.

# ---

# 2. Generate confusion matrix for different thresholds

# For this question, we will write a function that can answer the question: How many samples from
# the experiment dataframe belong to each of tp, tn, fp, fn groups, given some threshold.

# The function should calculate each of these four values for some choice of cut point or
# threshold. It should a data frame that consists of the four values and the cut point value.
# Together, these four values are called the "confusion matrix".

# Tip: Use as a model the following computation of the count of true positives:
# true positives: human called it positive, so did classifier
# tp = length( exp[ exp$human_crystal==TRUE & exp$class3_crystal > cut, "human_crystal"] )

# (Extra credit: In your function, also compute and return precision, accuracy, sensitivity, and specificity.
# Refer to an online source such as wikipedia for the formulae.)

# To call the function you write, use an R function called sapply(). This takes as arguments a list or
# vector, and a function that will be applied to each of the elements in that vector. Use the
# R help to find out more.

# Try some thresholds (cutpoints):
cutpoint = c(0.3,0.35,0.4,0.43,0.45,0.5)

# ANALYSIS:

# What makes a "good" classification? 

# Which cut points are better classification thresholds for this problem? Which are worse?

# ---

# 3. Kernel density comparison plots

# you will call the following function for several questions in this project focus:

compareDensityPlots <- function(neg, pos, w=FALSE) {

  # how many points in each subset?
  ln=length(neg)
  lp=length(pos)
  len = ln+lp

  # do weighting according to user selection
  posWt = NULL
  negWt = NULL
  yl=c(0,25)
  xl=c(0.3, 0.51)

  if (w==TRUE) {
    posWt = rep(1/len,lp)
    negWt = rep(1/len,ln)

    # a posteriori limits on x and y to enforce for weighted curves:
    yl=c(0,13)
    xl=c(0.3, 0.51)
  }

  # basic plot: non-crystal subset
  # use weight parameter to normalize the density we will draw.
  plot(density(neg,weights=negWt),
       col="blue",
       main="Weighted Density Curves of\nMachine and Human Classifications",
       xlab="Classifier Crystal Score",
       ylim=yl,
       xlim=xl)

  # the overplotting: crystal subset
  lines(density(pos,weights=posWt),
        col="red",
        ylim=yl,
        xlim=xl)

  grid(col="grey")

  legend(x="topright",
         title="Classification",
         c("Non-Crystal","Crystal"),
         fill=c("blue","red"))
}

# example call:
compareDensityPlots(neg, pos)


# Make a kernel density comparison plot of the crystal scores, by human classification.
# To do this, first make two subsets of the class3_crystal column, by the value of human_crystal.

# Next, call the provided function, compareDensityPlots(), passing the negative and positive 
# subsets, and specifying the parameter w=FALSE.

# ANALYSIS:
# Can you see the effect of the choice of threshold on the evaluation of the machine classifier? 
# If you want to maximize correct classifications, and minimize incorrect ones, what threshold 
# looks best based on your plot?

# ---

# 4. Class counts in the dataset

# Compute the counts of crystallized and non-crystallized proteins in the whole dataset.
# You should be able to use the subsets you found in the previous question.
# Based on the counts you have determined, does the kernel density comparison plot you created
# make sense? Why or why not?

# ---

# 5. Weighted kernel density comparison plot

# Repeat the call to the compareDensityPlots() function, passing the negative and positive 
# subsets, and now specifying the weight parameter w=TRUE in order to weight all points in 
# the dataset equally.

# ANALYSIS: Does this plot better reflect the class counts you have seen? Where do you think
# the best threshold will lie for the classifier? 
	
# ---

# 6. Histogram comparison plot of the classes.

# Now perform the same overplotting exercise using a histogram instead of a kernel density plot. 

# To overplot with histograms, generate a hist() object on each of the classes. Next, combine the two 
# histograms on a single set of axes. To do this, call plot() on the output of one hist() function, 
# then call plot() on the output of the other, specifying the parameter add=TRUE.

# Be sure to label your axes and the plot, color the two histograms so they can be distinguished,
# and use a call to legend() to label the classes.

# ---

# 7. ROC curve

# Compute a ROC curve of the classification results using the pROC R library. 

# First, compute a ROC object with a roc() call, then plot the ROC curve by passing the ROC 
# object to plot.roc(). In your plot, try specifying the print.auc and print.thresh parameters. 
# What do these do? Does the threshold that roc() computes agree with your conclusions from the 
# kernel density comparison plots?

# ANALYSIS:
# Make some remarks about the overall performance of the classifier, based on the ROC curve
# you created. Does the classifier perform better than random chance? How much better?

# Where do the other thresholds you computed put you on the ROC curve?


